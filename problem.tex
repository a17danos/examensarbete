\section{Problem}
\label{problem}

The problem is to benchmark and evaluate any significant performance improvements \parencite{HaasRossbergSchuffTitzerHolmanGohmanWagnerZakaiBastien2017,ReiserBlaser2017,Zakai2018} when using WebAssembly instead of JavaScript to implement algorithms commonly executed in modern web applications such as compression, encryption, sorting, floating point calculations, regular expressions, 2D and 3D rendering.

There are different ways to do this as described by \textcite{WohlinRunesonHostOhlssonRegnellWesslen2012}. One way would be to take an existing application and change the internals from JavaScript to WebAssembly and compare that from a end user perspective this would have the benefit of [...], but is not possible due to [...]. Another way would be to investigate perceived performance [...]. A third option taken in this thesis is to compile a set of tests into both JavaScript/asm.js and WebAssembly. Where each test represent a specific algorithm. Then run the all tests on a multitude of different web browsers on different platforms (desktop, tablets, and mobile phones), compare the result and reason about the differences.

% in modern web browsers as   leave to method

%The problem is Benchmarking WebAssembly. The research question is to determine if there is a significant performance difference between WebAssembly and JavaScript in the web browsers Chrome, Edge, Firefox and Safari on Windows and macOS.

%According to X WebAssembly is "faster". 
%Are there any particular algorithms that WebAssembly is faster than?
%Is there a difference between major web browsers?

\subsection{Hypothesis}

The hypothesis is that there is a significant difference ($\alpha = 0,01$) in performance between WebAssembly and JavaScript in all browsers on all platforms.

\hl{specific situation, e.g. less so when manipulating dom}

\subsection{Previous work}

WebAssembly performance has been measured before. \textcite{HaasRossbergSchuffTitzerHolmanGohmanWagnerZakaiBastien2017} use the Polyhedral Benchmark suite\footnote{http://web.cs.ucla.edu/~pouchet/software/polybench/} (PolyBench/C) to compare the execution time between native code and WebAssembly. They use Emscripten to generate WebAssembly and Clang \parencite{LattnerAdve2014} to compile regular application and then compares the two \parencite{HaasRossbergSchuffTitzerHolmanGohmanWagnerZakaiBastien2017}. \textcite{ReiserBlaser2017} use their own JavaScript-implementation, that tests wether the input is a prime or not, to compare the execution time between JavaScript and WebAssembly. They use their own compiler (speedy.js) to compile the same JavaScript-code to WebAssembly and compare the execution time between WebAssembly and JavaScript. \textcite{JangdaPowersGuhaBerger2019} developed and used a WebAssembly-version of BROWSIX to run unmodified unix application inside the browser and perform the SPEC CPU benchmark suite.

It seems that no one has previously investigated the difference between WebAssembly and JavaScript using one of the test suites that is traditionally used to test current JavaScript engines.

\begin{comment}
from wohlin

“Problem formulation. Based on the challenge(s) identified, the challenge should be formulated as a research problem and research questions should be specified. If several different challenges are identified there is a need to prioritize which to address. Furthermore, a main contact person for the chosen challenge should be identified. The person should preferably not only be appointed; it should be a person who would like to be the driver within the company and act as a champion for the research collaboration. This includes helping to get in contact with the right people in the company, and to help ensuring that the researchers get access to systems, documentation and data when needed.
As a natural part of the formulation of the research problem, the researchers conduct a literature search. This may be done as a systematic literature review as presented in Chap. 4. A literature survey is needed to know about existing approaches to the identified industrial challenge. It provides a basis for understanding the relationship between approaches available and the actual industrial needs.
Candidate solution. Based on available approaches and the actual needs, a candidate solution is developed, which may include tailoring to the current processes, methods, technologies[…]”
“he applicability can be continuously ensured. Although a specific solution for a company may be derived, the intention of the researcher is to develop a generic solution, which then is instantiated in a specific context.
Validation in academia. A first validation of the proposed solution is preferably conducted in an academic environment to minimize the risk, i.e. an off-line validation. In many cases this may be conducted as an experiment as described in several chapters of this book or as a case study of a student project. An overview of case study research is provided in Chap. 5. The validation in an academic environment may be conducted with either students as subjects or with representatives from the industrial partner(s).
The main objective in this step is to capture any obvious flaws in the proposed solution and to identify improvements proposals of the candidate solution. This is done in an academic setting to ensure that the best possible solution is available when bringing it to industry.
Static validation. In the static validation, industry representatives evaluate the candidate solution off-line. This may be done through a presentation of the candidate solution followed by either interviews of different industry[…]”
“how to conduct the validation depends on the type of solution. The new solution may be used in a project, a subproject or for parts of a system, or for a specific activity. Independently, it is recommended that the dynamic validation be followed closely to evaluate the solution. The dynamic solution may be studied using a case study approach as described in Chap. 5.
Release solution. A generic solution must be tailored to each unique situation. There is a need to ensure that any research solution is properly handed over to an industrial champion and that the company has sufficient support in terms of descriptions, training and potential tool support. The latter is not primarily the responsibility of the researchers, but they must support their collaborative partner(s) to ensure that the transfer of the new solution is properly in place and integrated into the organization before moving to the next industrial challenge.
Preferably, the broader usage is also studied empirically through a case study. This will help obtaining empirical evidence for the new solution developed in the research collaboration.
Concluding remark. The transfer model outlined illustrates how different empirical strategies may be applied to support transfer of new[…]”

Excerpt From: Claes Wohlin, Per Runeson, Martin Höst, Magnus C. Ohlsson, Björn Regnell and Anders Wesslén. “Experimentation in Software Engineering”. Apple Books. 
\end{comment}
